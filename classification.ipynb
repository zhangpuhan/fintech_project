{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ortho_group\n",
    "np.random.seed(seed=0)\n",
    "x = ortho_group.rvs(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_list = [1.5, 2.0, 1.5, 2.5, 1.7, 2.2]\n",
    "fdf = pd.DataFrame()\n",
    "for i in range(6):\n",
    "    fdf[i] = np.random.normal(loc=0.0, scale=std_list[i], size=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47669462,  0.15964814, -0.47766656,  0.55284255, -0.13930486,\n",
       "        0.44053222])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10813329, -0.8838343 ,  0.06718921,  0.39309219,  0.13141423,\n",
       "       -0.1756091 ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf[\"group\"] = 0.9 / (1.0 + np.exp(-np.matmul(fdf.values, x[0].T) + 5.0)) + 0.1 / (1.0 + np.exp(-np.matmul(fdf.values, x[1].T) + 6.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf[\"prob\"] = np.random.uniform(low=0.0, high=1.0, size=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf[\"label\"] = fdf[\"group\"] > fdf[\"prob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf[\"label\"] = fdf[\"label\"] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    193874\n",
       "1      6126\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = fdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = cdf.label.values\n",
    "X = cdf.drop([\"prob\", \"label\", \"group\"], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.2644018 ,  4.00259172,  1.99437553,  4.61904693, -0.53068814,\n",
       "         3.80792758],\n",
       "       [-1.09016515,  2.8152774 , -1.21269169, -1.9584467 ,  0.70623256,\n",
       "        -5.45471066],\n",
       "       [-0.30506562, -1.90167043,  2.04191504,  1.60608851, -0.04201549,\n",
       "         0.45122124],\n",
       "       ...,\n",
       "       [-0.11720379, -3.43795188, -1.89778315, -2.08164134, -1.4620388 ,\n",
       "        -0.640514  ],\n",
       "       [-0.80369369,  0.68150212, -0.10568412,  0.30215617, -0.23740226,\n",
       "         1.55757821],\n",
       "       [ 3.48005895,  1.83640184,  0.49217133, -0.84419194,  0.8227444 ,\n",
       "         0.31970732]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a14424d30>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.input = torch.nn.Linear(6, 2)\n",
    "        torch.nn.init.orthogonal_(self.input.weight)\n",
    "        self.output = torch.nn.Linear(2, 1, bias=False)\n",
    "        self.output.weight.data = torch.tensor([[0.9, 0.1]])\n",
    "        # self.input.weight.requires_grad = False\n",
    "        self.output.weight.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.input(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net_sub(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Net_sub, self).__init__()\n",
    "#         self.input = torch.nn.Linear(6, 1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.sigmoid(self.input(x))\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net_comb(torch.nn.Module):\n",
    "#     def __init__(self, Net_sub):\n",
    "#         super(Net_comb, self).__init__()\n",
    "#         self.net1 = Net_sub()\n",
    "#         self.net2 = Net_sub()\n",
    "#         self.weight = torch.nn.Parameter(torch.tensor(0.9))\n",
    "#         self.weight.requires_grad = False\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.cat((self.net1(x), self.net1(x)), 1)\n",
    "#         return self.weight * x[:, 0] + (1.0 - self.weight) * x[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_torch = torch.tensor(X)\n",
    "Y_torch = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_data_set = Data.TensorDataset(X_torch, Y_torch)\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_data_set,\n",
    "    batch_size=1000,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.Adam([net.input.bias], lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.4004,  0.5431, -0.1336,  0.5454,  0.2126,  0.4293],\n",
       "         [-0.2372, -0.6757, -0.4316, -0.0695,  0.1102,  0.5329]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([-0.3900, -0.2704], requires_grad=True), Parameter containing:\n",
       " tensor([[0.9000, 0.1000]])]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (input): Linear(in_features=6, out_features=2, bias=True)\n",
      "  (output): Linear(in_features=2, out_features=1, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_torch.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | loss:  0.10423806\n",
      "Parameter containing:\n",
      "tensor([[ 0.4322, -0.3311, -0.4010,  0.5134, -0.3519,  0.3948],\n",
      "        [ 0.0766,  0.7694, -0.0760,  0.4419,  0.3762,  0.2454]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  1 | loss:  0.105281085\n",
      "Parameter containing:\n",
      "tensor([[ 0.4412, -0.3239, -0.1394,  0.6809, -0.2330,  0.4045],\n",
      "        [ 0.0647,  0.7895, -0.5094,  0.1588,  0.1901,  0.2287]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  2 | loss:  0.10541792\n",
      "Parameter containing:\n",
      "tensor([[ 0.4625, -0.0574,  0.0867,  0.7777, -0.0264,  0.4126],\n",
      "        [ 0.0351,  0.3755, -0.8884, -0.0145, -0.1461,  0.2180]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  3 | loss:  0.10476339\n",
      "Parameter containing:\n",
      "tensor([[ 0.4653,  0.3676,  0.0334,  0.6655,  0.1403,  0.4305],\n",
      "        [ 0.0350, -0.3061, -0.8178,  0.1510, -0.4212,  0.1913]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  4 | loss:  0.104535185\n",
      "Parameter containing:\n",
      "tensor([[ 0.4384,  0.5661, -0.2258,  0.4747,  0.1328,  0.4404],\n",
      "        [ 0.0777, -0.6405, -0.4166,  0.4506, -0.4211,  0.1740]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  5 | loss:  0.103941165\n",
      "Parameter containing:\n",
      "tensor([[ 0.4092,  0.5553, -0.4533,  0.3507,  0.0563,  0.4395],\n",
      "        [ 0.1218, -0.6536, -0.0569,  0.6552, -0.3111,  0.1713]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  6 | loss:  0.10301706\n",
      "Parameter containing:\n",
      "tensor([[ 0.3725,  0.4493, -0.6321,  0.2964, -0.0399,  0.4135],\n",
      "        [ 0.1775, -0.5157,  0.2393,  0.7586, -0.1660,  0.2068]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  7 | loss:  0.10199854\n",
      "Parameter containing:\n",
      "tensor([[ 0.3166,  0.2581, -0.7651,  0.3148, -0.1522,  0.3551],\n",
      "        [ 0.2671, -0.2300,  0.4763,  0.7489,  0.0133,  0.2975]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  8 | loss:  0.102011085\n",
      "Parameter containing:\n",
      "tensor([[ 0.2465, -0.0035, -0.7787,  0.4252, -0.2580,  0.2935],\n",
      "        [ 0.3866,  0.1944,  0.5261,  0.5814,  0.1931,  0.4016]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  9 | loss:  0.10358162\n",
      "Parameter containing:\n",
      "tensor([[ 0.2137, -0.2160, -0.6379,  0.5735, -0.3097,  0.2768],\n",
      "        [ 0.4503,  0.5622,  0.3100,  0.3330,  0.2878,  0.4382]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  10 | loss:  0.10503648\n",
      "Parameter containing:\n",
      "tensor([[ 0.2313, -0.3085, -0.4465,  0.6746, -0.3161,  0.3123],\n",
      "        [ 0.4309,  0.7399, -0.0028,  0.1524,  0.3057,  0.3884]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  11 | loss:  0.10565464\n",
      "Parameter containing:\n",
      "tensor([[ 0.3007, -0.3134, -0.2235,  0.7148, -0.3096,  0.3941],\n",
      "        [ 0.3249,  0.7702, -0.3737,  0.0714,  0.2998,  0.2591]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  12 | loss:  0.104562044\n",
      "Parameter containing:\n",
      "tensor([[ 0.4722, -0.1252,  0.0523,  0.6448, -0.2449,  0.5325],\n",
      "        [ 0.0511,  0.4816, -0.8342,  0.1732,  0.1978,  0.0315]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  13 | loss:  0.10364609\n",
      "Parameter containing:\n",
      "tensor([[ 0.6129,  0.3351,  0.0242,  0.4520, -0.0482,  0.5528],\n",
      "        [-0.1794, -0.2642, -0.8057,  0.4843, -0.1213, -0.0119]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  14 | loss:  0.103990644\n",
      "Parameter containing:\n",
      "tensor([[ 0.5694,  0.5258, -0.2425,  0.3811,  0.0573,  0.4389],\n",
      "        [-0.1171, -0.5945, -0.3847,  0.6072, -0.2999,  0.1639]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  15 | loss:  0.10368694\n",
      "Parameter containing:\n",
      "tensor([[ 0.5183,  0.5319, -0.4132,  0.3812,  0.0776,  0.3565],\n",
      "        [-0.0419, -0.6335, -0.1090,  0.6163, -0.3437,  0.2962]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  16 | loss:  0.103153616\n",
      "Parameter containing:\n",
      "tensor([[ 0.4807,  0.4854, -0.5358,  0.3847,  0.0707,  0.3066],\n",
      "        [ 0.0122, -0.5864,  0.0967,  0.6195, -0.3438,  0.3811]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  17 | loss:  0.10247462\n",
      "Parameter containing:\n",
      "tensor([[ 0.4330,  0.3941, -0.6561,  0.3904,  0.0472,  0.2697],\n",
      "        [ 0.0849, -0.4630,  0.3074,  0.6186, -0.3167,  0.4491]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  18 | loss:  0.10182968\n",
      "Parameter containing:\n",
      "tensor([[ 0.3489,  0.2102, -0.7774,  0.4042, -0.0161,  0.2584],\n",
      "        [ 0.2224, -0.1758,  0.5288,  0.6034, -0.2212,  0.4771]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  19 | loss:  0.10212728\n",
      "Parameter containing:\n",
      "tensor([[ 0.2299, -0.0772, -0.7803,  0.4589, -0.1435,  0.3190],\n",
      "        [ 0.4265,  0.3085,  0.5571,  0.5161, -0.0111,  0.3832]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  20 | loss:  0.10425167\n",
      "Parameter containing:\n",
      "tensor([[ 0.1653, -0.2865, -0.5570,  0.5597, -0.2775,  0.4369],\n",
      "        [ 0.5454,  0.6827,  0.1923,  0.3445,  0.2182,  0.1844]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  21 | loss:  0.105423704\n",
      "Parameter containing:\n",
      "tensor([[ 0.1938, -0.2851, -0.2722,  0.6369, -0.3521,  0.5275],\n",
      "        [ 0.5072,  0.7032, -0.2886,  0.2081,  0.3488,  0.0268]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  22 | loss:  0.105033964\n",
      "Parameter containing:\n",
      "tensor([[ 0.2959, -0.1217, -0.0280,  0.6591, -0.3779,  0.5661],\n",
      "        [ 0.3446,  0.4456, -0.7050,  0.1636,  0.3970, -0.0443]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  23 | loss:  0.10367183\n",
      "Parameter containing:\n",
      "tensor([[ 0.4688,  0.1806,  0.0950,  0.6104, -0.3129,  0.5185],\n",
      "        [ 0.0627, -0.0502, -0.9221,  0.2379,  0.2943,  0.0277]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  24 | loss:  0.103214405\n",
      "Parameter containing:\n",
      "tensor([[ 0.6072,  0.4367, -0.0332,  0.5121, -0.1520,  0.3936],\n",
      "        [-0.1686, -0.4831, -0.7259,  0.3973,  0.0315,  0.2306]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  25 | loss:  0.10328063\n",
      "Parameter containing:\n",
      "tensor([[ 0.6440,  0.4886, -0.2615,  0.4336, -0.0166,  0.3010],\n",
      "        [-0.2387, -0.5903, -0.3576,  0.5290, -0.1953,  0.3864]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  26 | loss:  0.102925174\n",
      "Parameter containing:\n",
      "tensor([[ 0.6290,  0.4161, -0.4615,  0.3841,  0.0606,  0.2604],\n",
      "        [-0.2265, -0.4949, -0.0253,  0.6176, -0.3319,  0.4607]],\n",
      "       requires_grad=True)\n",
      "******************************************\n",
      "Epoch:  27 | loss:  0.1023713\n",
      "Parameter containing:\n",
      "tensor([[ 0.5727,  0.2764, -0.6272,  0.3550,  0.0926,  0.2617],\n",
      "        [-0.1456, -0.2800,  0.2619,  0.6760, -0.3972,  0.4667]],\n",
      "       requires_grad=True)\n",
      "******************************************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-276-c5bd57df603b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    for step, (X_train, Y_train) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        X_train = X_train.requires_grad_(True)\n",
    "\n",
    "        logistic_regression_result = net(X_train.float())\n",
    "        loss = F.binary_cross_entropy(logistic_regression_result, Y_train.unsqueeze(1).float())\n",
    "        \n",
    "        # print('Epoch: ', epoch, '| Step: ', step, '| loss_1: ', loss_1)\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        weight_partial = net.input.weight.grad\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            matA = torch.mm(torch.transpose(weight_partial, 0, 1), net.input.weight) - torch.mm(torch.transpose(net.input.weight, 0, 1), weight_partial)\n",
    "            update_matrix = torch.mm(torch.inverse(torch.eye(6) + matA * lr / 2.0), (torch.eye(6) - matA * lr / 2.0))\n",
    "            updated_weight = torch.mm(update_matrix, torch.transpose(net.input.weight, 0, 1))\n",
    "        optimizer.step()\n",
    "        net.input.weight.data = torch.transpose(updated_weight, 0, 1)\n",
    "        \n",
    "        \n",
    "    with torch.no_grad():\n",
    "        loss_all = F.binary_cross_entropy(net(X_torch.float()), Y_torch.unsqueeze(1).float())\n",
    "        print('Epoch: ', epoch,'| loss: ', loss_all.data.numpy())\n",
    "        print(net.input.weight)\n",
    "        print(\"******************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.4296, -0.1699, -0.6077,  0.3673, -0.3829,  0.3693],\n",
      "        [ 0.0829,  0.4723,  0.2530,  0.6746,  0.4088,  0.2904]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-4.9933, -4.0897], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.9000, 0.1000]])\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.47669462  0.15964814 -0.47766656  0.55284255 -0.13930486  0.44053222]\n",
      "[ 0.10813329 -0.8838343   0.06718921  0.39309219  0.13141423 -0.1756091 ]\n"
     ]
    }
   ],
   "source": [
    "print(x[0])\n",
    "print(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00014147999999994387"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[0] * a[1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': [Parameter containing:\n",
      "tensor([-5.6412, -3.5738], requires_grad=True)], 'lr': 0.01, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}\n"
     ]
    }
   ],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    print(param_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
